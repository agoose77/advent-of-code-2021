{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104aab3f-7060-40a9-be94-2d95ecf93311",
   "metadata": {
    "papermill": {
     "duration": 0.031208,
     "end_time": "2021-12-08T13:48:27.629778",
     "exception": false,
     "start_time": "2021-12-08T13:48:27.598570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Day 16: BITS\n",
    "The input for this problem is located at https://adventofcode.com/2021/day/16/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756033ca-4204-4f3e-b8b5-3ec3271becfa",
   "metadata": {
    "lines_to_next_cell": 1,
    "papermill": {
     "duration": 0.035933,
     "end_time": "2021-12-08T13:48:27.700199",
     "exception": false,
     "start_time": "2021-12-08T13:48:27.664266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import binascii\n",
    "import enum\n",
    "import io\n",
    "import operator\n",
    "import typing\n",
    "\n",
    "%load_ext numpy_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48baf3-f296-4a35-b70d-cb48e733b8a9",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "We *could* solve this with ASCII text, but I'd prefer to implement a *proper* solution using a bit-stream. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13748463-15e1-4acc-928a-c16b59fe4cde",
   "metadata": {},
   "source": [
    "### Reading bits from a bytes stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d8f9c8-e82d-4ef2-ad49-c6c518bab1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bit_mask(n: int) -> int:\n",
    "    return (1 << n) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f197f282-0a9b-4dd6-9650-9d1d0c360978",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitStream:\n",
    "    def __init__(self, stream: io.IOBase):\n",
    "        self._stream = stream\n",
    "        self._offset = 0\n",
    "\n",
    "    @classmethod\n",
    "    def from_bytes(cls, bytes_):\n",
    "        return cls(io.BytesIO(bytes_))\n",
    "\n",
    "    @property\n",
    "    def offset(self) -> int:\n",
    "        return self._offset\n",
    "\n",
    "    @property\n",
    "    def location(self) -> tuple[int, int]:\n",
    "        return divmod(self._offset, 8)\n",
    "\n",
    "    def skip_bits(self, n: int):\n",
    "        self._offset += n\n",
    "\n",
    "    def seek_next_byte(self):\n",
    "        self._offset += 8 - (self._offset % 8)\n",
    "\n",
    "    def read_integer(self, n_bits: int) -> int:\n",
    "        byte_start, bit_start = divmod(self._offset, 8)\n",
    "        self._offset += n_bits\n",
    "        byte_end, bit_end = divmod(self._offset, 8)\n",
    "        self._stream.seek(byte_start)\n",
    "        content = int.from_bytes(self._stream.read((byte_end + 1) - byte_start), \"big\")\n",
    "        return (content >> (8 - bit_end)) & bit_mask(n_bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032cb79-19e1-4188-868a-6ab6fcb02de4",
   "metadata": {},
   "source": [
    "### Generating events\n",
    "We could create a parse tree here. However, to support partial reads, I'd prefer to implement an event stream, where the reading can stop before all packets are consumed from the byte stream. This event stream is unsurprisingly comprised of \"events\", with packet boundaries to permit reconstruction of the parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac228882-9597-4ef4-995c-dbf5a389407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamEvent(enum.Enum):\n",
    "    BEGIN_PACKET = enum.auto()\n",
    "    READ_UNTIL = enum.auto()\n",
    "    READ_SEVERAL = enum.auto()\n",
    "    EMIT_VALUE = enum.auto()\n",
    "    END_PACKET = enum.auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26fb89-e7b6-4aae-8979-5374642e73c3",
   "metadata": {},
   "source": [
    "As indicated, to read a literal we build an integer from repeated shifts of the non-contiguous chunks. This process finishes with the generation of a `EMIT_VALUE` event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24ea981e-f980-439c-baa5-42ab10224609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_literal(stream):\n",
    "    chunks = []\n",
    "    while True:\n",
    "        is_last = not stream.read_integer(1)\n",
    "        chunks.append(stream.read_integer(4))\n",
    "        if is_last:\n",
    "            break\n",
    "\n",
    "    value = 0\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        shift = (len(chunks) - (i + 1)) * 4\n",
    "        value |= chunk << shift\n",
    "    yield StreamEvent.EMIT_VALUE, value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dae478-32be-42ef-beff-8141524de551",
   "metadata": {},
   "source": [
    "To read an operator, we switch on the type bit, before generating a type-specific event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e913c6b-68ae-477b-b805-a55cc8c55d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_operator(stream):\n",
    "    mode = stream.read_integer(1)\n",
    "    if mode:\n",
    "        n_packets = stream.read_integer(11)\n",
    "        yield StreamEvent.READ_SEVERAL, n_packets\n",
    "        for i in range(n_packets):\n",
    "            yield from read_packet(stream)\n",
    "    else:\n",
    "        length = stream.read_integer(15)\n",
    "        yield StreamEvent.READ_UNTIL, length\n",
    "\n",
    "        start = stream.offset\n",
    "        while stream.offset < length + start:\n",
    "            yield from read_packet(stream)\n",
    "        assert stream.offset == length + start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5845b324-1f02-4dd9-ad74-8f395cc48cbd",
   "metadata": {},
   "source": [
    "The header is common to all packets, so we create a nice type for it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f53ccfd-0223-4d71-8000-99bdaa51d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PacketHeader(typing.NamedTuple):\n",
    "    version: int\n",
    "    type: int\n",
    "\n",
    "\n",
    "def read_packet_header(stream):\n",
    "    version = stream.read_integer(3)\n",
    "    type_ = stream.read_integer(3)\n",
    "    return PacketHeader(version, type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be956f73-7d8d-4606-b89e-819f78ff97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_packet(stream):\n",
    "    header = read_packet_header(stream)\n",
    "    yield (StreamEvent.BEGIN_PACKET, header, stream.location)\n",
    "\n",
    "    # Read contents\n",
    "    if header.type == 4:\n",
    "        yield from read_literal(stream)\n",
    "    else:\n",
    "        yield from read_operator(stream)\n",
    "\n",
    "    # Indicate end of packet\n",
    "    yield (StreamEvent.END_PACKET, header, stream.location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca4e262-d4b4-4c02-8d41-bfa423faabd7",
   "metadata": {
    "papermill": {
     "duration": 0.033761,
     "end_time": "2021-12-08T13:48:27.771840",
     "exception": false,
     "start_time": "2021-12-08T13:48:27.738079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a4a8d5f-d52f-43cc-b23a-e694acc77ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\") as f:\n",
    "    data = b\"\".join([binascii.unhexlify(l) for l in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cdc139c-9423-418f-9f89-851a2f689ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = read_packet(BitStream.from_bytes(data))\n",
    "headers = (ev[1] for ev in events if ev[0] == StreamEvent.BEGIN_PACKET)\n",
    "sum(h.version for h in headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c1745-2958-4c02-8692-88570cc1077b",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b4e6e-87f4-4a4e-bb34-1eca92bc5a75",
   "metadata": {},
   "source": [
    "### Packet Types\n",
    "We have a concrete set of operator packet types. Let's enumerate them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86d40f15-937f-4ca8-9a64-1f303885cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PacketType(enum.IntEnum):\n",
    "    SUM = 0\n",
    "    PRODUCT = 1\n",
    "    MINIMUM = 2\n",
    "    MAXIMUM = 3\n",
    "    VALUE = 4\n",
    "    GREATER_THAN = 5\n",
    "    LESS_THAN = 6\n",
    "    EQUAL_TO = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ebd135-504d-4960-b5cb-0c66bcc9f4c0",
   "metadata": {},
   "source": [
    "Each operator type has an associated reducer type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7766a772-10a2-4d75-964f-71b9fdbe9edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE_TO_REDUCER = {\n",
    "    PacketType.SUM: operator.add,\n",
    "    PacketType.PRODUCT: operator.mul,\n",
    "    PacketType.MINIMUM: min,\n",
    "    PacketType.MAXIMUM: max,\n",
    "    PacketType.GREATER_THAN: operator.gt,\n",
    "    PacketType.LESS_THAN: operator.lt,\n",
    "    PacketType.EQUAL_TO: operator.eq,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b48009-f71f-4dea-8f54-8a2e85d7cb89",
   "metadata": {},
   "source": [
    "To process the event stream, we can use a stack machine. For simple value packets, we can just push their contents to the stack. For operator packets, we need a bit more logic. Operator packets should reduce their arguments (the stack) at the end of the packet (`END_PACKET`). In order to do this without maintaining a history of the processed events, we can push a sentinel value to the stack upon entering an operator packet, such that reduction is terminated upon encountering this object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d6e8abe-589f-4973-842f-b9a924d7835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Sentinel(typing.NamedTuple):\n",
    "    kind: str\n",
    "\n",
    "\n",
    "REDUCE_SENTINEL = _Sentinel(\"REDUCE_STOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107995d6-276d-49a5-8c63-300d2300483e",
   "metadata": {},
   "source": [
    "The stack logic is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb02905-ab00-407f-b7b7-22289723bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transmission(events):\n",
    "    stack = []\n",
    "\n",
    "    for event, *payload in events:\n",
    "        if event == StreamEvent.EMIT_VALUE:\n",
    "            stack.append(payload[0])\n",
    "        elif event == StreamEvent.BEGIN_PACKET and payload[0].type != PacketType.VALUE:\n",
    "            stack.append(REDUCE_SENTINEL)\n",
    "        elif event == StreamEvent.END_PACKET:\n",
    "            header = payload[0]\n",
    "            reducer = TYPE_TO_REDUCER.get(header.type)\n",
    "            if reducer is None:\n",
    "                continue\n",
    "\n",
    "            while True:\n",
    "                b = stack.pop()\n",
    "                a = stack.pop()\n",
    "                if a is REDUCE_SENTINEL:\n",
    "                    break\n",
    "                stack.append(reducer(a, b))\n",
    "            stack.append(b)\n",
    "    return stack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d10a1599-f5b8-485f-b00c-3e64aeae8b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10626195124371"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = read_packet(BitStream.from_bytes(data))\n",
    "\n",
    "evaluate_transmission(events)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.067522,
   "end_time": "2021-12-08T13:48:29.482469",
   "environment_variables": {},
   "exception": null,
   "input_path": "08-segments/01-multi-pass.ipynb",
   "output_path": "08-segments/01-multi-pass.ipynb",
   "parameters": {},
   "start_time": "2021-12-08T13:48:26.414947",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
